{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86182d11-e222-4dc7-8af5-3ffa3a927e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from importlib import reload  \n",
    "import numpy as np\n",
    "import torch,time\n",
    "from transformers import BartModel,BartConfig,BartForConditionalGeneration,BartForCausalLM\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b195ea-9934-4ecf-b54b-e096c439e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "  \n",
    "# setting path to enable import from the parent directory\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3647212-f6c0-4bb4-a44e-68f2f83e0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, score_at_min1=0,patience=100, verbose=False, delta=0, path='checkpoint.pt',\n",
    "                 trace_func=print,save_epochwise=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = score_at_min1\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.state_dict_list=[None]*patience\n",
    "        self.improved=0\n",
    "        self.stop_update=0\n",
    "        self.save_model_counter=0\n",
    "        self.save_epochwise=save_epochwise\n",
    "        self.times_improved=0\n",
    "        self.activated=False\n",
    "    def activate(self,s1,s2):\n",
    "        if not self.activated and s1>0 and s2>0: self.activated=True\n",
    "    def __call__(self, score, epoch,model):\n",
    "        if not self.activated: return None\n",
    "        self.save_model_counter = (self.save_model_counter + 1) % 4\n",
    "        if not self.stop_update:\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'\\033[91m The val score  of epoch {epoch} is {score:.4f} \\033[0m')\n",
    "            if score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                self.trace_func(f'\\033[93m EarlyStopping counter: {self.counter} out of {self.patience} \\033[0m')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "                self.improved=0\n",
    "            else:\n",
    "                self.save_checkpoint(score, model,epoch)\n",
    "                self.best_score = score\n",
    "                self.counter = 0\n",
    "                self.improved=1\n",
    "        else:\n",
    "            self.improved=0 #not needed though\n",
    "\n",
    "    def save_checkpoint(self, score, model,epoch):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        # if self.verbose:\n",
    "        self.times_improved+=1\n",
    "        self.trace_func(f'\\033[92m Validation score improved ({self.best_score:.4f} --> {score:.4f}). \\033[0m')\n",
    "        if self.save_epochwise:\n",
    "            path=self.path+\"_\"+str(self.times_improved)+\"_\"+str(epoch)\n",
    "        else:\n",
    "            path=self.path\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ceb6ba7-a1dd-4806-ad0b-9d9b0c3d8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import make_dataset\n",
    "import pathlib\n",
    "train=make_dataset(pathlib.Path(\"../data/protechn_corpus_eval/train/\"))\n",
    "val=make_dataset(pathlib.Path(\"../data/protechn_corpus_eval/dev/\"))\n",
    "test=make_dataset(pathlib.Path(\"../data/protechn_corpus_eval/test/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9e6bb0-c5ca-4d79-9e53-33965ff44e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a8a72f-1a8e-4f20-b8a5-103c46a576b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import make_bert_dataset,make_bert_testset\n",
    "train_=make_bert_testset(train)\n",
    "val_=make_bert_testset(val)\n",
    "test_=make_bert_testset(test)\n",
    "train_sents=[ list(map(lambda x: x[1] if x[0]==0 else \" \"+x[1], enumerate(i))) for d in train_[0] for i in d]\n",
    "val_sents=[ list(map(lambda x: x[1] if x[0]==0 else \" \"+x[1], enumerate(i))) for d in val_[0] for i in d]\n",
    "test_sents=[ list(map(lambda x: x[1] if x[0]==0 else \" \"+x[1], enumerate(i))) for d in test_[0] for i in d]\n",
    "def create_labels(dataset):\n",
    "    temp=[ set(i)-set(\"O\") for d in dataset[1] for i in d]\n",
    "    return [ next(iter(i)) if len(i)>0 else \"O\"  for i in temp]\n",
    "train_ls=create_labels(train_)\n",
    "val_ls=create_labels(val_)\n",
    "test_ls=create_labels(test_)\n",
    "train_y_txt=[ i for d in train_[1] for i in d]\n",
    "val_y_txt=[ i for d in val_[1] for i in d]\n",
    "test_y_txt=[ i for d in test_[1] for i in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabafab5-aab5-495f-ae3e-85ed83edf97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set={'Appeal_to_Authority',\n",
    " 'Appeal_to_fear-prejudice',\n",
    " 'Bandwagon',\n",
    " 'Black-and-White_Fallacy',\n",
    " 'Causal_Oversimplification',\n",
    " 'Doubt',\n",
    " 'Exaggeration,Minimisation',\n",
    " 'Flag-Waving',\n",
    " 'Loaded_Language',\n",
    " 'Name_Calling,Labeling',\n",
    " 'O',\n",
    " 'Obfuscation,Intentional_Vagueness,Confusion',\n",
    " 'Red_Herring',\n",
    " 'Reductio_ad_hitlerum',\n",
    " 'Repetition',\n",
    " 'Slogans',\n",
    " 'Straw_Men',\n",
    " 'Thought-terminating_Cliches',\n",
    " 'Whataboutism'}\n",
    "train_idx_bylabel={x: [i for i in range(len(train_ls)) if train_ls[i]==x] for x in labels_set} \n",
    "val_idx_bylabel={x: [i for i in range(len(val_ls)) if val_ls[i]==x] for x in labels_set} \n",
    "test_idx_bylabel={x: [i for i in range(len(test_ls)) if test_ls[i]==x] for x in labels_set} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24cbc76-be6b-4749-a243-29d0f3a16799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x,y,y_txt,it_is_train=1,pos_or_neg=None,fix_seq_len=256,balance=False,\n",
    "                 specific_label=None,for_protos=False):\n",
    "        self.x=[]\n",
    "        self.attn_mask=[]\n",
    "        self.labels_mask=[]\n",
    "        self.y_txt=[]\n",
    "        self.y=[]\n",
    "        self.labels_ids={}\n",
    "        for i in labels_set:\n",
    "            self.labels_ids[i]=len(self.labels_ids)\n",
    "        self.y_fine_int=[]\n",
    "        it_is_train_proxy=it_is_train\n",
    "        for split_sent,y_tags,y_sent in zip(x,y_txt,y):\n",
    "            if specific_label is not None and specific_label!=y_sent: continue\n",
    "            if pos_or_neg==\"pos\" and y_sent==\"O\": continue\n",
    "            elif pos_or_neg==\"neg\" and y_sent!=\"O\": continue                \n",
    "            if y_sent==\"O\":\n",
    "                it_is_train=0\n",
    "            else:\n",
    "                it_is_train=it_is_train_proxy               \n",
    "            tmp=tokenizer(split_sent,is_split_into_words=False)[\"input_ids\"]\n",
    "            tmp_x=[]\n",
    "            tmp_attn=[]\n",
    "            tmp_y=[]\n",
    "            for i,chunk in enumerate(tmp):\n",
    "                if for_protos and y_tags[i]==\"O\":\n",
    "                    continue\n",
    "                tmp_y.extend([y_tags[i]]*len(chunk))\n",
    "                if y_tags[i]!=\"O\":\n",
    "                    mask=1\n",
    "                else:\n",
    "                    if it_is_train:\n",
    "                        mask=0\n",
    "                    else:\n",
    "                        mask=1\n",
    "                tmp_x.extend(chunk[1:-1])\n",
    "                tmp_attn.extend([mask]*(len(chunk)-2))\n",
    "            tmp_x.append(tokenizer.eos_token_id)\n",
    "            tmp_x.insert(0,tokenizer.bos_token_id)\n",
    "            tmp_attn.append(tmp_attn[-1])\n",
    "            tmp_attn.insert(0,tmp_attn[0])\n",
    "            self.x.append(tmp_x)\n",
    "            self.attn_mask.append(tmp_attn)\n",
    "            self.y_txt.append(tmp_y)\n",
    "            self.y.append(1 if y_sent!=\"O\" else 0)\n",
    "            self.y_fine_int.append(self.labels_ids[y_sent])\n",
    "        for tokid_sent in self.x:\n",
    "            tokid_sent.extend([tokenizer.pad_token_id]*(fix_seq_len-len(tokid_sent)))\n",
    "        for mask_vec in self.attn_mask:\n",
    "            mask_vec.extend([0]*(fix_seq_len-len(mask_vec)))\n",
    "        if balance:\n",
    "            num_pos=np.sum(self.y)\n",
    "            assert num_pos<len(self.y_fine_int)//2\n",
    "            \n",
    "            pos_indices=np.random.choice([i for i in range(len(self.y)) if self.y[i]==1],\n",
    "                                         size=len(self.y)-2*num_pos,replace=True)\n",
    "            self.x.extend([self.x[i] for i in pos_indices])\n",
    "            self.y.extend([1 for i in pos_indices])\n",
    "            self.y_fine_int.extend([self.y_fine_int[i] for i in pos_indices])\n",
    "            self.attn_mask.extend([self.attn_mask[i] for i in pos_indices])\n",
    "        self.fix_seq_len=fix_seq_len\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx],self.attn_mask[idx],self.y[idx]\n",
    "    def collate_fn(self,batch):        \n",
    "        return (torch.LongTensor([i[0] for i in batch]),\n",
    "                torch.Tensor([i[1] for i in batch]),\n",
    "                torch.LongTensor([i[2] for i in batch]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5012b7a8-5ac6-42a6-b5c5-1de4f3b15c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=BinaryClassDataset(train_sents,train_ls,train_y_txt,it_is_train=0,balance=True)\n",
    "val_dataset=BinaryClassDataset(val_sents,val_ls,val_y_txt,it_is_train=0)\n",
    "test_dataset=BinaryClassDataset(test_sents,test_ls,test_y_txt,it_is_train=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "517c1969-3d65-4a23-aca2-12d9cb034fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl=torch.utils.data.DataLoader(train_dataset,batch_size=20,shuffle=True,\n",
    "                                     collate_fn=train_dataset.collate_fn)\n",
    "val_dl=torch.utils.data.DataLoader(val_dataset,batch_size=128,shuffle=False,\n",
    "                                     collate_fn=val_dataset.collate_fn)\n",
    "test_dl=torch.utils.data.DataLoader(test_dataset,batch_size=128,shuffle=False,\n",
    "                                     collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8127b463-edb2-4301-8063-f8793d2b5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logs(file,info,epoch,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1):\n",
    "    logs=[]\n",
    "    s=\" \".join((info+\" epoch\",str(epoch),\"Total loss %.4f\"%(val_loss),\"\\n\"))\n",
    "    logs.append(s)\n",
    "    print(s)\n",
    "    s=\" \".join((info+\" epoch\",str(epoch),\"Prec\",str(mac_val_prec),\"\\n\"))\n",
    "    logs.append(s)\n",
    "    print(s)\n",
    "    s=\" \".join((info+\" epoch\",str(epoch),\"Recall\",str(mac_val_rec),\"\\n\"))\n",
    "    logs.append(s)\n",
    "    print(s)\n",
    "    s=\" \".join((info+\" epoch\",str(epoch),\"F1\",str(mac_val_f1),\"\\n\"))\n",
    "    logs.append(s)\n",
    "    print(s)\n",
    "#     print(\"epoch\",epoch,\"MICRO val precision %.4f, recall %.4f, f1 %.4f,\"%(mic_val_prec,mic_val_rec,mic_val_f1))\n",
    "    print() \n",
    "    logs.append(\"\\n\")\n",
    "    f=open(file,\"a\")\n",
    "    f.writelines(logs)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e8ba21-15d4-4bed-92ef-a40531dd1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def evaluate(dl,model_new=None,path=None,modelclass=None):\n",
    "    assert (model_new is not None) ^ (path is not None)\n",
    "    if path is not None:\n",
    "        model_new=modelclass().cuda()\n",
    "        model_new.load_state_dict(torch.load(path))\n",
    "    loader = tqdm(dl, total=len(dl), unit=\"batches\")\n",
    "    total_len=0\n",
    "    model_new.eval()    \n",
    "    with torch.no_grad():\n",
    "        total_loss=0\n",
    "        tts=0\n",
    "        y_pred=[]\n",
    "        y_true=[]\n",
    "        for batch in loader:\n",
    "            input_ids,attn_mask,y=batch\n",
    "            classfn_out,loss=model_new(input_ids,attn_mask,y,use_decoder=False,use_classfn=1)\n",
    "            if classfn_out.ndim==1:\n",
    "                predict=torch.zeros_like(y)\n",
    "                predict[classfn_out>0]=1\n",
    "            else:\n",
    "                predict=torch.argmax(classfn_out,dim=1)\n",
    "                \n",
    "            y_pred.append(predict.cpu().numpy())\n",
    "            y_true.append(y.cpu().numpy())\n",
    "            total_loss+=(len(input_ids)*loss[0].item())\n",
    "            total_len+=len(input_ids)\n",
    "        total_loss=total_loss/total_len\n",
    "        mac_prec,mac_recall,mac_f1_score,_=precision_recall_fscore_support(np.concatenate(y_true),np.concatenate(y_pred),labels=[0,1])\n",
    "        mic_prec,mic_recall,mic_f1_score,_=0,0,0,0\n",
    "\n",
    "    return total_loss,mac_prec,mac_recall,mac_f1_score,mic_prec,mic_recall,mic_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ae2e4c-4e43-4a4c-9d25-f0e0f7254e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prototypes=20\n",
    "num_pos_protos=19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a88b8d2-1700-48eb-b86b-6535ace7886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleProtoBartModel(torch.nn.Module):\n",
    "    def __init__(self,n_classes=2):\n",
    "        super().__init__()\n",
    "        self.bart_model=BartForConditionalGeneration.from_pretrained('facebook/bart-large')   \n",
    "        self.bart_out_dim=self.bart_model.config.d_model\n",
    "        self.max_position_embeddings=256\n",
    "        self.num_protos=num_prototypes\n",
    "        self.prototypes=torch.nn.Parameter(torch.rand(self.num_protos,self.max_position_embeddings,self.bart_out_dim))\n",
    "        self.classfn_model=torch.nn.Linear(self.num_protos,2)\n",
    "        self.loss_fn=torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        \n",
    "        self.set_encoder_status(True)\n",
    "        self.set_decoder_status(False)\n",
    "        self.set_protos_status(False)\n",
    "        self.set_classfn_status(False)\n",
    "        \n",
    "        self.BNLayer=torch.nn.BatchNorm1d(self.num_protos)\n",
    "        \n",
    "    def set_encoder_status(self,status=True):\n",
    "        self.num_enc_layers=len(self.bart_model.base_model.encoder.layers)\n",
    "        for (i,x) in enumerate(self.bart_model.base_model.encoder.layers):\n",
    "            requires_grad=False\n",
    "            if i==self.num_enc_layers-1: requires_grad=status\n",
    "            for y in x.parameters():\n",
    "                y.requires_grad=requires_grad\n",
    "    def set_decoder_status(self,status=True):\n",
    "        self.num_dec_layers=len(self.bart_model.base_model.decoder.layers)\n",
    "        for (i,x) in enumerate(self.bart_model.base_model.decoder.layers):\n",
    "            requires_grad=False\n",
    "            if i==self.num_dec_layers-1: requires_grad=status\n",
    "            for y in x.parameters():\n",
    "                y.requires_grad=requires_grad\n",
    "    def set_classfn_status(self,status=True):\n",
    "        self.classfn_model.requires_grad=status\n",
    "    def set_protos_status(self,status=True):\n",
    "        self.prototypes.requires_grad=status       \n",
    "        \n",
    "\n",
    "    def forward(self,input_ids,attn_mask,y,use_decoder=1,use_classfn=0,use_rc=0,use_p1=0,use_p2=0,rc_loss_lamb=0.95,p1_lamb=0.93,p2_lamb=0.92):\n",
    "        batch_size=input_ids.size(0)\n",
    "        if use_decoder:\n",
    "            labels=input_ids.cuda()+0 \n",
    "            labels[labels==self.bart_model.config.pad_token_id]=-100\n",
    "            bart_output=self.bart_model(labels,attn_mask.cuda(),labels=labels,\n",
    "                                        output_attentions=False,output_hidden_states=False)\n",
    "            rc_loss,last_hidden_state=batch_size*bart_output.loss,bart_output.encoder_last_hidden_state\n",
    "        else:\n",
    "            rc_loss=0\n",
    "            last_hidden_state=self.bart_model.base_model.encoder(input_ids.cuda(),attn_mask.cuda(),\n",
    "                                                                 output_attentions=False,\n",
    "                                                                 output_hidden_states=False).last_hidden_state\n",
    "        input_for_classfn,l_p1,l_p2,classfn_out,classfn_loss=None,0,0,None,0\n",
    "        if use_classfn or use_p1 or use_p2:\n",
    "            input_for_classfn=torch.cdist(last_hidden_state.view(batch_size,-1),\n",
    "                                          self.prototypes.view(self.num_protos,-1))\n",
    "        if use_p1:\n",
    "            l_p1=torch.mean(torch.min(input_for_classfn,dim=0)[0])\n",
    "        if use_p2:            \n",
    "            l_p2=torch.mean(torch.min(input_for_classfn,dim=1)[0])\n",
    "        if use_classfn:\n",
    "            classfn_out=self.classfn_model(input_for_classfn).view(batch_size,2)\n",
    "            classfn_loss=self.loss_fn(classfn_out,y.cuda())\n",
    "        if not use_rc:\n",
    "            rc_loss=0\n",
    "        total_loss=classfn_loss+rc_loss_lamb*rc_loss+p1_lamb*l_p1+p2_lamb*l_p2\n",
    "        # return classfn_out,total_loss \n",
    "        return classfn_out, (total_loss, classfn_loss.detach().cpu(), rc_loss, l_p1,\n",
    "                             l_p2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df84b349-e680-458b-96fc-01eba9216f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()        \n",
    "model=SimpleProtoBartModel().cuda()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "modelname=\"apr_22_5_simpleprotobart_onlyclass_80_20_train_nomask_protos_yesmask_enc_on\"\n",
    "save_path=\"../Models/\"+modelname\n",
    "logs_path=\"../Logs/\"+modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23a8610d-7440-4435-a1d4-e119d36b4b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf69aeb497b4ecf828d7aa1e1d3e53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch -1 Total loss 75.4986 \n",
      "\n",
      "VAL SCORES epoch -1 Prec [0.66666667 0.        ] \n",
      "\n",
      "VAL SCORES epoch -1 Recall [1. 0.] \n",
      "\n",
      "VAL SCORES epoch -1 F1 [0.8 0. ] \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0de31e7ff34a33b3c9fbed9a051c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch -1 Total loss 113.2461 \n",
      "\n",
      "TRAIN SCORES epoch -1 Prec [0.5 0. ] \n",
      "\n",
      "TRAIN SCORES epoch -1 Recall [1. 0.] \n",
      "\n",
      "TRAIN SCORES epoch -1 F1 [0.66666667 0.        ] \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5c3cd760524663ad3c2a6bceaa2ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db99b15ebfe743d096ff9cb5ab747f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 0 Total loss 0.6968 \n",
      "\n",
      "TRAIN SCORES epoch 0 Prec [0.50227205 0.76744186] \n",
      "\n",
      "TRAIN SCORES epoch 0 Recall [0.99608189 0.01292977] \n",
      "\n",
      "TRAIN SCORES epoch 0 F1 [0.66780496 0.02543108] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90bf7fc93084e18ac811afb697a0fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 0 Total loss 0.6788 \n",
      "\n",
      "VAL SCORES epoch 0 Prec [0.66799007 0.71428571] \n",
      "\n",
      "VAL SCORES epoch 0 Recall [0.99851632 0.0074184 ] \n",
      "\n",
      "VAL SCORES epoch 0 F1 [0.80047577 0.01468429] \n",
      "\n",
      "\n",
      "\u001b[92m Validation score improved (-inf --> 0.4076). \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7097a799de249b58be21f876f0c3b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORES epoch 0 Total loss 0.6711 \n",
      "\n",
      "TEST SCORES epoch 0 Prec [0.73568726 0.44444444] \n",
      "\n",
      "TEST SCORES epoch 0 Recall [0.99658353 0.00757576] \n",
      "\n",
      "TEST SCORES epoch 0 F1 [0.84648868 0.01489758] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3f677a832340b2886cd7c6675335a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9dc52b69a84651a818620778f92e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 1 Total loss 0.7017 \n",
      "\n",
      "TRAIN SCORES epoch 1 Prec [0.5 0. ] \n",
      "\n",
      "TRAIN SCORES epoch 1 Recall [1. 0.] \n",
      "\n",
      "TRAIN SCORES epoch 1 F1 [0.66666667 0.        ] \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4751aeaede1347e8aa09755f2feaff6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 1 Total loss 0.6688 \n",
      "\n",
      "VAL SCORES epoch 1 Prec [0.66666667 0.        ] \n",
      "\n",
      "VAL SCORES epoch 1 Recall [1. 0.] \n",
      "\n",
      "VAL SCORES epoch 1 F1 [0.8 0. ] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 1 out of 7 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b41bbdd71304c6da704372ac22ea8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cf1e067e944761953720d4e1741b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 2 Total loss 0.6985 \n",
      "\n",
      "TRAIN SCORES epoch 2 Prec [0.  0.5] \n",
      "\n",
      "TRAIN SCORES epoch 2 Recall [0. 1.] \n",
      "\n",
      "TRAIN SCORES epoch 2 F1 [0.         0.66666667] \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0883b61f2744bd592ef83f6261491cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 2 Total loss 0.7365 \n",
      "\n",
      "VAL SCORES epoch 2 Prec [0.         0.33333333] \n",
      "\n",
      "VAL SCORES epoch 2 Recall [0. 1.] \n",
      "\n",
      "VAL SCORES epoch 2 F1 [0.  0.5] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 2 out of 7 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98092584b99a40849cb34154e8488ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e688e9b8dd4c4696228f4126f5fd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 3 Total loss 0.6934 \n",
      "\n",
      "TRAIN SCORES epoch 3 Prec [0.5 0. ] \n",
      "\n",
      "TRAIN SCORES epoch 3 Recall [1. 0.] \n",
      "\n",
      "TRAIN SCORES epoch 3 F1 [0.66666667 0.        ] \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebfdaa1beec40a1a4e82693b289672e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 3 Total loss 0.6584 \n",
      "\n",
      "VAL SCORES epoch 3 Prec [0.66666667 0.        ] \n",
      "\n",
      "VAL SCORES epoch 3 Recall [1. 0.] \n",
      "\n",
      "VAL SCORES epoch 3 F1 [0.8 0. ] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 3 out of 7 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb29743db80477dbcca4fe8516a05c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe178334e664278a92e09e6d971669e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 4 Total loss 0.7073 \n",
      "\n",
      "TRAIN SCORES epoch 4 Prec [0.  0.5] \n",
      "\n",
      "TRAIN SCORES epoch 4 Recall [0. 1.] \n",
      "\n",
      "TRAIN SCORES epoch 4 F1 [0.         0.66666667] \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398deeced9794bb6acf221030dc8d211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 4 Total loss 0.7696 \n",
      "\n",
      "VAL SCORES epoch 4 Prec [0.         0.33333333] \n",
      "\n",
      "VAL SCORES epoch 4 Recall [0. 1.] \n",
      "\n",
      "VAL SCORES epoch 4 F1 [0.  0.5] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 4 out of 7 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f79e1228a884bce90e81f5862db5a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORES (not the best ones) epoch 4 Total loss 0.7928 \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 4 Prec [0.         0.26512679] \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 4 Recall [0. 1.] \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 4 F1 [0.         0.41913078] \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc966b715d184fc2b06acd17044233b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f873e21e26934c6b8eb839f0d8e81b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 5 Total loss 0.6828 \n",
      "\n",
      "TRAIN SCORES epoch 5 Prec [0.  0.5] \n",
      "\n",
      "TRAIN SCORES epoch 5 Recall [0. 1.] \n",
      "\n",
      "TRAIN SCORES epoch 5 F1 [0.         0.66666667] \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdafad122fe4ad0a2615c0d03113c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 5 Total loss 0.7187 \n",
      "\n",
      "VAL SCORES epoch 5 Prec [0.         0.33333333] \n",
      "\n",
      "VAL SCORES epoch 5 Recall [0. 1.] \n",
      "\n",
      "VAL SCORES epoch 5 F1 [0.  0.5] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 5 out of 7 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872ea18c982945a59119af63b21433a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa156d052c54e6dbe520faf3f12d730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 6 Total loss 0.6698 \n",
      "\n",
      "TRAIN SCORES epoch 6 Prec [0.59942956 0.78060651] \n",
      "\n",
      "TRAIN SCORES epoch 6 Recall [0.88519933 0.40846312] \n",
      "\n",
      "TRAIN SCORES epoch 6 F1 [0.71481115 0.53629992] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00121edd50f344858f6a6ece880a803f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 6 Total loss 0.6442 \n",
      "\n",
      "VAL SCORES epoch 6 Prec [0.68295218 0.65306122] \n",
      "\n",
      "VAL SCORES epoch 6 Recall [0.97477745 0.09495549] \n",
      "\n",
      "VAL SCORES epoch 6 F1 [0.80317848 0.16580311] \n",
      "\n",
      "\n",
      "\u001b[92m Validation score improved (0.4076 --> 0.4845). \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a35a50300fc45fa93cc6ac324dca8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORES epoch 6 Total loss 0.6277 \n",
      "\n",
      "TEST SCORES epoch 6 Prec [0.75242083 0.67901235] \n",
      "\n",
      "TEST SCORES epoch 6 Recall [0.98223437 0.10416667] \n",
      "\n",
      "TEST SCORES epoch 6 F1 [0.85210433 0.18062397] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd5a6dbaca2416da70625a7e7c24991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1c8164479140d19fc5f7b9ce0924a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 7 Total loss 0.6663 \n",
      "\n",
      "TRAIN SCORES epoch 7 Prec [0.70825433 0.63172623] \n",
      "\n",
      "TRAIN SCORES epoch 7 Recall [0.54882946 0.77392497] \n",
      "\n",
      "TRAIN SCORES epoch 7 F1 [0.61843267 0.69563303] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad3ec99f4134915b9bf7e564e45db90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 7 Total loss 0.6644 \n",
      "\n",
      "VAL SCORES epoch 7 Prec [0.81367041 0.49790356] \n",
      "\n",
      "VAL SCORES epoch 7 Recall [0.64465875 0.70474777] \n",
      "\n",
      "VAL SCORES epoch 7 F1 [0.71937086 0.58353808] \n",
      "\n",
      "\n",
      "\u001b[92m Validation score improved (0.4845 --> 0.6515). \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a265beaf0234b42bfa0db5b9d454a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORES epoch 7 Total loss 0.6593 \n",
      "\n",
      "TEST SCORES epoch 7 Prec [0.85440457 0.45656434] \n",
      "\n",
      "TEST SCORES epoch 7 Recall [0.71574991 0.66193182] \n",
      "\n",
      "TEST SCORES epoch 7 F1 [0.7789552  0.54039428] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9618c1bbc5f84a83987baf11a88466a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34cc2aebb1549a08f365a35e37adc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 8 Total loss 0.6716 \n",
      "\n",
      "TRAIN SCORES epoch 8 Prec [0.52441805 0.79538165] \n",
      "\n",
      "TRAIN SCORES epoch 8 Recall [0.96875306 0.12146146] \n",
      "\n",
      "TRAIN SCORES epoch 8 F1 [0.68047337 0.21074099] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04791675cd0048599f6a21d15c73de4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 8 Total loss 0.6243 \n",
      "\n",
      "VAL SCORES epoch 8 Prec [0.67758444 0.64705882] \n",
      "\n",
      "VAL SCORES epoch 8 Recall [0.98219585 0.0652819 ] \n",
      "\n",
      "VAL SCORES epoch 8 F1 [0.80193822 0.11859838] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 1 out of 7 \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d170bda2e58643b48b0c685f57b7e0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dd1819dab84567935abc8fc39d56fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 9 Total loss 0.6829 \n",
      "\n",
      "TRAIN SCORES epoch 9 Prec [0.51298371 0.8277635 ] \n",
      "\n",
      "TRAIN SCORES epoch 9 Recall [0.98687433 0.06308159] \n",
      "\n",
      "TRAIN SCORES epoch 9 F1 [0.67506449 0.11722945] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea7c738066e45c2b8970b437f674611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 9 Total loss 0.6125 \n",
      "\n",
      "VAL SCORES epoch 9 Prec [0.6694831 0.9      ] \n",
      "\n",
      "VAL SCORES epoch 9 Recall [0.99925816 0.01335312] \n",
      "\n",
      "VAL SCORES epoch 9 F1 [0.80178571 0.02631579] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 2 out of 7 \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6837dfb74014678a8629c3172418c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORES (not the best ones) epoch 9 Total loss 0.5765 \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 9 Prec [0.73918543 0.83333333] \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 9 Recall [0.99829177 0.02367424] \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 9 F1 [0.8494186  0.04604052] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c67300b3f74d45950d9dd1e613ef4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711dc359341d432eba73c676fc782e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 10 Total loss 0.6671 \n",
      "\n",
      "TRAIN SCORES epoch 10 Prec [0.56791672 0.74217352] \n",
      "\n",
      "TRAIN SCORES epoch 10 Recall [0.88706044 0.3251053 ] \n",
      "\n",
      "TRAIN SCORES epoch 10 F1 [0.6924871  0.45214904] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72467d886f504c4a8672276aa539846f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 10 Total loss 0.6434 \n",
      "\n",
      "VAL SCORES epoch 10 Prec [0.73233271 0.58156028] \n",
      "\n",
      "VAL SCORES epoch 10 Recall [0.86869436 0.36498516] \n",
      "\n",
      "VAL SCORES epoch 10 F1 [0.79470648 0.4484959 ] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 3 out of 7 \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cc73c7ac8b4b5d89b74b1ad77308c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e00f9478723431a924cdba7e0cade7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 11 Total loss 0.6680 \n",
      "\n",
      "TRAIN SCORES epoch 11 Prec [0.65937378 0.66173278] \n",
      "\n",
      "TRAIN SCORES epoch 11 Recall [0.66421785 0.65687139] \n",
      "\n",
      "TRAIN SCORES epoch 11 F1 [0.66178695 0.65929312] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1298fc91efdb4d38ae37adbe22d33061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 11 Total loss 0.6533 \n",
      "\n",
      "VAL SCORES epoch 11 Prec [0.76892744 0.50530504] \n",
      "\n",
      "VAL SCORES epoch 11 Recall [0.72329377 0.5652819 ] \n",
      "\n",
      "VAL SCORES epoch 11 F1 [0.74541284 0.53361345] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 4 out of 7 \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fa07bdc2574bfba9449cfdea4232b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93171e2755b46b7b368385c9340e225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 12 Total loss 0.6753 \n",
      "\n",
      "TRAIN SCORES epoch 12 Prec [0.52913411 0.77039275] \n",
      "\n",
      "TRAIN SCORES epoch 12 Recall [0.95533353 0.14986776] \n",
      "\n",
      "TRAIN SCORES epoch 12 F1 [0.68105164 0.25092251] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd55b74b11346ffac53ea3c23c3cd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 12 Total loss 0.6250 \n",
      "\n",
      "VAL SCORES epoch 12 Prec [0.67015446 0.8       ] \n",
      "\n",
      "VAL SCORES epoch 12 Recall [0.99777448 0.01780415] \n",
      "\n",
      "VAL SCORES epoch 12 F1 [0.80178838 0.03483309] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 5 out of 7 \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720f6393403e46738c9e2244f9c9885d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddb6cf9e7c34206838805a3a5d72edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 13 Total loss 0.6845 \n",
      "\n",
      "TRAIN SCORES epoch 13 Prec [0.52624882 0.70269116] \n",
      "\n",
      "TRAIN SCORES epoch 13 Recall [0.93182486 0.16113233] \n",
      "\n",
      "TRAIN SCORES epoch 13 F1 [0.67262957 0.26215139] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e8022d0b074745adb43974e8920009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 13 Total loss 0.6911 \n",
      "\n",
      "VAL SCORES epoch 13 Prec [0.75804376 0.39036145] \n",
      "\n",
      "VAL SCORES epoch 13 Recall [0.43694362 0.72106825] \n",
      "\n",
      "VAL SCORES epoch 13 F1 [0.55435294 0.50651381] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 6 out of 7 \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0546d7df9d2a4ac4822d219381d40c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066ba073b1544bb29637ce6f7c802fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 14 Total loss 0.6914 \n",
      "\n",
      "TRAIN SCORES epoch 14 Prec [0.50231916 0.80921053] \n",
      "\n",
      "TRAIN SCORES epoch 14 Recall [0.99715937 0.01204819] \n",
      "\n",
      "TRAIN SCORES epoch 14 F1 [0.6680886  0.02374288] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03c85abad754753a10dad85b28500b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 14 Total loss 0.7047 \n",
      "\n",
      "VAL SCORES epoch 14 Prec [0.67666232 0.33944223] \n",
      "\n",
      "VAL SCORES epoch 14 Recall [0.38501484 0.63204748] \n",
      "\n",
      "VAL SCORES epoch 14 F1 [0.49078014 0.44167963] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 7 out of 7 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "simple protobart\n",
    "\"\"\"\n",
    "from transformers.optimization import AdamW\n",
    "# optim=torch.optim.Adam(model.parameters(),lr=5e-5,weight_decay=0.01)\n",
    "optim=AdamW(model.parameters(),lr=3e-5,weight_decay=0.01,eps=1e-8)\n",
    "f=open(logs_path,\"w\")\n",
    "f.writelines([\"\"])\n",
    "f.close()\n",
    "epoch=-1\n",
    "val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(val_dl,model)\n",
    "print_logs(logs_path,\"VAL SCORES\",epoch,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(train_dl,model)\n",
    "print_logs(logs_path,\"TRAIN SCORES\",epoch,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "es=EarlyStopping(-np.inf,patience=7,path=save_path,save_epochwise=False)\n",
    "n_iters=500\n",
    "for epoch in range(n_iters):\n",
    "    total_loss=0\n",
    "    model.train()\n",
    "    model.set_encoder_status(status=True)\n",
    "    model.set_decoder_status(status=False)\n",
    "    model.set_protos_status(status=True)\n",
    "    model.set_classfn_status(status=True)\n",
    "    classfn_loss,rc_loss,l_p1,l_p2,l_p3=[0]*5\n",
    "    train_loader = tqdm(train_dl, total=len(train_dl), unit=\"batches\",desc=\"training\")\n",
    "    for batch in train_loader:\n",
    "        input_ids,attn_mask,y=batch\n",
    "        classfn_out,loss=model(input_ids,attn_mask,y,use_decoder=0,use_classfn=1,\n",
    "                               use_rc=0,use_p1=1,use_p2=1,rc_loss_lamb=1.0,p1_lamb=1.0,\n",
    "                               p2_lamb=1.0)\n",
    "        loss[0].backward()\n",
    "        optim.step()\n",
    "        classfn_out=None\n",
    "        loss=None\n",
    "    total_loss=total_loss/len(train_dataset)\n",
    "    val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(train_dl,model)\n",
    "    print_logs(logs_path,\"TRAIN SCORES\",epoch,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "    es.activate(mac_val_f1[0],mac_val_f1[1])\n",
    "    val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(val_dl,model)\n",
    "    print_logs(logs_path,\"VAL SCORES\",epoch,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "    es((mac_val_f1[1]+mac_val_f1[0])/2,epoch,model)\n",
    "    if es.early_stop:\n",
    "        break\n",
    "    if es.improved:\n",
    "        \"\"\"\n",
    "        Below using \"val_\" prefix but the dl is that of test.\n",
    "        \"\"\"\n",
    "        val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(test_dl,model)\n",
    "        print_logs(logs_path,\"TEST SCORES\",epoch,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "    elif (epoch+1)%5==0:\n",
    "        \"\"\"\n",
    "        Below using \"val_\" prefix but the dl is that of test.\n",
    "        \"\"\"\n",
    "        val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(test_dl,model)\n",
    "        print_logs(logs_path,\"TEST SCORES (not the best ones)\",epoch,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1c3091-f37d-4562-8c03-ec77524e623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegProtoBartModel(torch.nn.Module):\n",
    "    def __init__(self,n_classes=2,bias=True,dropout=False,special_classfn=False,p=0.5,batchnormlp1=False):\n",
    "        super().__init__()\n",
    "        self.bart_model=BartForConditionalGeneration.from_pretrained('facebook/bart-large') \n",
    "        self.bart_out_dim=self.bart_model.config.d_model\n",
    "        self.one_by_sqrt_bartoutdim=1/torch.sqrt(torch.tensor(self.bart_out_dim).float())\n",
    "        self.max_position_embeddings=256\n",
    "        self.num_protos=num_prototypes\n",
    "        self.num_pos_protos=num_pos_protos\n",
    "        self.num_neg_protos=self.num_protos-self.num_pos_protos\n",
    "        self.pos_prototypes=torch.nn.Parameter(torch.rand(self.num_pos_protos,self.max_position_embeddings,self.bart_out_dim))\n",
    "        self.neg_prototypes=torch.nn.Parameter(torch.rand(self.num_neg_protos,self.max_position_embeddings,self.bart_out_dim))\n",
    "        self.classfn_model=torch.nn.Linear(self.num_protos,2,bias=bias)\n",
    "        self.loss_fn=torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        \n",
    "        self.do_dropout=dropout\n",
    "        self.special_classfn=special_classfn\n",
    "        \n",
    "        self.dropout=torch.nn.Dropout(p=p)\n",
    "        self.dobatchnorm=batchnormlp1\n",
    "        self.distance_grounder = torch.zeros(2, self.num_protos).cuda()\n",
    "        self.distance_grounder[0][:self.num_pos_protos] = 1e7\n",
    "        self.distance_grounder[1][self.num_pos_protos:] = 1e7\n",
    "\n",
    "    \n",
    "    def set_prototypes(self,do_random=False):\n",
    "        if do_random:\n",
    "            print(\"initializing prototypes with xavier init\")\n",
    "            torch.nn.init.xavier_normal_(self.pos_prototypes)\n",
    "            torch.nn.init.xavier_normal_(self.neg_prototypes)\n",
    "        else:\n",
    "            print(\"initializing prototypes with encoded outputs\")\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                self.pos_prototypes=torch.nn.Parameter(\n",
    "                    self.bart_model.base_model.encoder(input_ids_pos_rdm.cuda(),\n",
    "                                                       attn_mask_pos_rdm.cuda(),\n",
    "                                                       output_attentions=False,\n",
    "                                                       output_hidden_states=False).last_hidden_state)\n",
    "                self.neg_prototypes=torch.nn.Parameter(\n",
    "                    self.bart_model.base_model.encoder(input_ids_neg_rdm.cuda(),\n",
    "                                                       attn_mask_neg_rdm.cuda(),\n",
    "                                                       output_attentions=False,\n",
    "                                                       output_hidden_states=False).last_hidden_state)\n",
    "    \n",
    "    def set_shared_status(self,status=True):\n",
    "        print(\"ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\")\n",
    "        self.bart_model.model.shared.requires_grad_(status)\n",
    "\n",
    "    def set_encoder_status(self,status=True):\n",
    "        self.num_enc_layers=len(self.bart_model.base_model.encoder.layers)\n",
    "        for i in range(self.num_enc_layers):\n",
    "            self.bart_model.base_model.encoder.layers[i].requires_grad_(False)\n",
    "        self.bart_model.base_model.encoder.layers[self.num_enc_layers-1].requires_grad_(status)\n",
    "        return\n",
    "    def set_decoder_status(self,status=True):\n",
    "        self.num_dec_layers=len(self.bart_model.base_model.decoder.layers)\n",
    "        for i in range(self.num_dec_layers):\n",
    "            self.bart_model.base_model.decoder.layers[i].requires_grad_(False)\n",
    "        self.bart_model.base_model.decoder.layers[self.num_dec_layers-1].requires_grad_(status)\n",
    "        return\n",
    "    def set_classfn_status(self,status=True):\n",
    "        self.classfn_model.requires_grad_(status)\n",
    "\n",
    "    def set_protos_status(self,pos_or_neg=None,status=True):\n",
    "        if pos_or_neg==\"pos\" or pos_or_neg is None:\n",
    "            self.pos_prototypes.requires_grad=status       \n",
    "        if pos_or_neg==\"neg\" or pos_or_neg is None:\n",
    "            self.neg_prototypes.requires_grad=status       \n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attn_mask, y, use_decoder=1, use_classfn=0, use_rc=0, use_p1=0, use_p2=0,\n",
    "                use_p3=0, classfn_lamb=1.0, rc_loss_lamb=0.95, p1_lamb=0.93, p2_lamb=0.92, p3_lamb=1.0,\n",
    "                distmask_lp1=0,distmask_lp2=0,\n",
    "                pos_or_neg=None,random_mask_for_distanceMat=None):\n",
    "        \"\"\"\n",
    "            1. p3_loss is the prototype-distance-maximising loss. See the set of lines after the line \"if use_p3:\"\n",
    "            2. We also have flags distmask_lp1 and distmask_lp2 which uses \"masked\" distance matrix for calculating lp1 and lp2 loss.\n",
    "            3. the flag \"random_mask_for_distanceMat\" is an experimental part. It randomly masks (artificially inflates) \n",
    "            random places in the distance matrix so as to encourage more prototypes be \"discovered\" by the training \n",
    "            examples.\n",
    "        \"\"\"\n",
    "        batch_size = input_ids.size(0)\n",
    "        if use_decoder:\n",
    "            labels = input_ids.cuda() + 0\n",
    "            labels[labels == self.bart_model.config.pad_token_id] = -100\n",
    "            bart_output = self.bart_model(input_ids.cuda(), attn_mask.cuda(), labels=labels,\n",
    "                                          output_attentions=False, output_hidden_states=False)\n",
    "            rc_loss, last_hidden_state = bart_output.loss, bart_output.encoder_last_hidden_state\n",
    "        else:\n",
    "            rc_loss = torch.tensor(0)\n",
    "            last_hidden_state = self.bart_model.base_model.encoder(input_ids.cuda(), attn_mask.cuda(),\n",
    "                                                                   output_attentions=False,\n",
    "                                                                   output_hidden_states=False).last_hidden_state\n",
    "        input_for_classfn, l_p1, l_p2, l_p3, l_p4, classfn_out, classfn_loss = (None, torch.tensor(0), torch.tensor(0),\n",
    "                                                                                torch.tensor(0), torch.tensor(0), None,\n",
    "                                                                                torch.tensor(0))\n",
    "        if use_classfn or use_p1 or use_p2 or use_p3:\n",
    "            all_protos = torch.cat((self.pos_prototypes, self.neg_prototypes), dim=0)\n",
    "            if use_classfn or use_p1 or use_p2:\n",
    "                if not self.dobatchnorm:\n",
    "                    input_for_classfn = self.one_by_sqrt_bartoutdim * torch.cdist(last_hidden_state.view(batch_size, -1),\n",
    "                                                                                  all_protos.view(self.num_protos, -1))\n",
    "                else:\n",
    "                    input_for_classfn = torch.cdist(last_hidden_state.view(batch_size, -1),\n",
    "                                                    all_protos.view(self.num_protos, -1))\n",
    "                    input_for_classfn= torch.nn.functional.instance_norm(\n",
    "                        input_for_classfn.view(batch_size,1,self.num_protos)).view(batch_size,\n",
    "                                                                                   self.num_protos)\n",
    "            if use_p1 or use_p2:\n",
    "                distance_mask = self.distance_grounder[y.cuda()]\n",
    "                input_for_classfn_masked = input_for_classfn+distance_mask\n",
    "                if random_mask_for_distanceMat:\n",
    "                    random_mask=torch.bernoulli(torch.ones_like(input_for_classfn_masked)*\n",
    "                                                random_mask_for_distanceMat).bool()\n",
    "                    input_for_classfn_masked[random_mask]=1e7\n",
    "        if use_p1:\n",
    "            l_p1 = torch.mean(torch.min(input_for_classfn_masked if distmask_lp1 else input_for_classfn, dim=0)[0])\n",
    "        if use_p2:\n",
    "            l_p2 = torch.mean(torch.min(input_for_classfn_masked if distmask_lp2 else input_for_classfn, dim=1)[0])\n",
    "        if use_p3:\n",
    "            l_p3 = self.one_by_sqrt_bartoutdim * torch.mean(torch.pdist(\n",
    "                self.pos_prototypes.view(self.num_pos_protos,-1)))\n",
    "        if use_classfn:\n",
    "            if self.do_dropout:\n",
    "                if self.special_classfn:\n",
    "                    classfn_out = (input_for_classfn@self.classfn_model.weight.t()+\n",
    "                                   self.dropout(self.classfn_model.bias.repeat(batch_size,1))).view(batch_size, 2)\n",
    "                else:\n",
    "                    classfn_out = self.classfn_model(self.dropout(input_for_classfn)).view(batch_size, 2)\n",
    "            else:\n",
    "                classfn_out = self.classfn_model(input_for_classfn).view(batch_size, 2)\n",
    "            classfn_loss = self.loss_fn(classfn_out, y.cuda())\n",
    "        if not use_rc:\n",
    "            rc_loss = torch.tensor(0)\n",
    "        total_loss = classfn_lamb * classfn_loss + rc_loss_lamb * rc_loss + p1_lamb * l_p1 + p2_lamb * l_p2 - p3_lamb * l_p3\n",
    "        return classfn_out, (total_loss, classfn_loss.detach().cpu(), rc_loss.detach().cpu(), l_p1.detach().cpu(),\n",
    "                             l_p2.detach().cpu(), l_p3.detach().cpu())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df9c9a4c-f945-4df5-8b05-7c75bf4c4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing prototypes with xavier init\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "modelname=\"NegProtoTEx_protos_xavier_large_bs20_20_woRat_noReco_g2d_nobias_nodrop_cu1_PosUp_normed\"\n",
    "model=NegProtoBartModel(bias=False,dropout=False,special_classfn=False,p=0.75,batchnormlp1=True).cuda()\n",
    "model.set_prototypes(do_random=True)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "save_path=\"../Models/\"+modelname\n",
    "logs_path=\"../Logs/\"+modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb20877-aca8-4173-a1d9-78ea0a00bd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/05773/anubrata/ls6/anaconda3/envs/prototex/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255bd8ce889e491c8317e4cf36e9dbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch -1 Total loss 0.6991 \n",
      "\n",
      "VAL SCORES epoch -1 Prec [0.66610313 0.33253874] \n",
      "\n",
      "VAL SCORES epoch -1 Recall [0.58456973 0.41394659] \n",
      "\n",
      "VAL SCORES epoch -1 F1 [0.62267878 0.3688037 ] \n",
      "\n",
      "\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac131f953ca4d799157f59802e43ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f10e3842ff4508b028849c0e35d16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f4638cf78f4228a6bc0d6a35657d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7290803362064406b7cffebeec59a9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 0 Total loss 0.5415 \n",
      "\n",
      "TRAIN SCORES epoch 0 Prec [0.72415233 0.81785883] \n",
      "\n",
      "TRAIN SCORES epoch 0 Recall [0.84934861 0.67646195] \n",
      "\n",
      "TRAIN SCORES epoch 0 F1 [0.78176982 0.7404707 ] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5605283edc8b4ec1a3df9145f91ac571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 0 Total loss 0.5486 \n",
      "\n",
      "VAL SCORES epoch 0 Prec [0.82295574 0.63570392] \n",
      "\n",
      "VAL SCORES epoch 0 Recall [0.81379822 0.64985163] \n",
      "\n",
      "VAL SCORES epoch 0 F1 [0.81835136 0.64269993] \n",
      "\n",
      "\n",
      "\u001b[92m Validation score improved (-inf --> 0.7305). \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e15af9092d04508999c739ef373d649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORES epoch 0 Total loss 0.5277 \n",
      "\n",
      "TEST SCORES epoch 0 Prec [0.87032506 0.61051693] \n",
      "\n",
      "TEST SCORES epoch 0 Recall [0.85070038 0.64867424] \n",
      "\n",
      "TEST SCORES epoch 0 F1 [0.86040083 0.62901745] \n",
      "\n",
      "\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ff352573e54fa4a803645ce9179179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902bf8f9e1384d5c9246750744f836b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6193d26287ea47dfb5288a54de42949e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159c300b63254cc5913c10de94511fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 1 Total loss 0.4709 \n",
      "\n",
      "TRAIN SCORES epoch 1 Prec [0.86798455 0.77883953] \n",
      "\n",
      "TRAIN SCORES epoch 1 Recall [0.74835929 0.88617886] \n",
      "\n",
      "TRAIN SCORES epoch 1 F1 [0.8037452  0.82904926] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff5223c2a22452e8131a6ff5d0b1af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 1 Total loss 0.5545 \n",
      "\n",
      "VAL SCORES epoch 1 Prec [0.88480155 0.5611729 ] \n",
      "\n",
      "VAL SCORES epoch 1 Recall [0.67804154 0.82344214] \n",
      "\n",
      "VAL SCORES epoch 1 F1 [0.76774465 0.66746843] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 1 out of 7 \u001b[0m\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00d554af1ed43d5822da93a9a147eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4582a80672e42fabb21d326fe5a9656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480810f6d33443f89a9c2c2dfa8e26f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69f8477276f4b46bb93b6f4fba5775e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 2 Total loss 0.3603 \n",
      "\n",
      "TRAIN SCORES epoch 2 Prec [0.84648467 0.88119728] \n",
      "\n",
      "TRAIN SCORES epoch 2 Recall [0.88686453 0.83916152] \n",
      "\n",
      "TRAIN SCORES epoch 2 F1 [0.86620426 0.85966585] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45244c1726e146eeab624744d861b783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 2 Total loss 0.4940 \n",
      "\n",
      "VAL SCORES epoch 2 Prec [0.82813688 0.63366337] \n",
      "\n",
      "VAL SCORES epoch 2 Recall [0.8078635  0.66468843] \n",
      "\n",
      "VAL SCORES epoch 2 F1 [0.81787458 0.64880521] \n",
      "\n",
      "\n",
      "\u001b[92m Validation score improved (0.7305 --> 0.7333). \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dae26b0f904a098a9d07daf37a7f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORES epoch 2 Total loss 0.4493 \n",
      "\n",
      "TEST SCORES epoch 2 Prec [0.8812095  0.60248963] \n",
      "\n",
      "TEST SCORES epoch 2 Recall [0.83635121 0.6875    ] \n",
      "\n",
      "TEST SCORES epoch 2 F1 [0.85819457 0.64219372] \n",
      "\n",
      "\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ca0ddca4cd407193a7a75285064463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df31a0fb6ee54c0289e86cbc67229efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bd6c605e5d440aadd99e22dc8ff2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3687e45d632f4244a7b9784e115ee91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 3 Total loss 0.3423 \n",
      "\n",
      "TRAIN SCORES epoch 3 Prec [0.90573069 0.88406902] \n",
      "\n",
      "TRAIN SCORES epoch 3 Recall [0.88088941 0.90831619] \n",
      "\n",
      "TRAIN SCORES epoch 3 F1 [0.89313735 0.8960286 ] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e8f52e5eee40cf8b97ae1082a983fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 3 Total loss 0.5284 \n",
      "\n",
      "VAL SCORES epoch 3 Prec [0.83452665 0.60915033] \n",
      "\n",
      "VAL SCORES epoch 3 Recall [0.77818991 0.69139466] \n",
      "\n",
      "VAL SCORES epoch 3 F1 [0.80537428 0.64767199] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 1 out of 7 \u001b[0m\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fca16be93e42b6a0f7c47d1126d79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd0cbd84be045f5b82c49e0eb279c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7e305666b3452b89bcd4a2f1931f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5f52fb45ae4532897196bc08123234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 4 Total loss 0.3482 \n",
      "\n",
      "TRAIN SCORES epoch 4 Prec [0.97803347 0.78629601] \n",
      "\n",
      "TRAIN SCORES epoch 4 Recall [0.73268684 0.98354393] \n",
      "\n",
      "TRAIN SCORES epoch 4 F1 [0.8377667  0.87392837] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62adb3ef17164c42911312b7e08e208b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 4 Total loss 0.7024 \n",
      "\n",
      "VAL SCORES epoch 4 Prec [0.8835691  0.51405258] \n",
      "\n",
      "VAL SCORES epoch 4 Recall [0.60237389 0.84124629] \n",
      "\n",
      "VAL SCORES epoch 4 F1 [0.71636524 0.63815419] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 2 out of 7 \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7827a1c3d24f8c9eb98bc4f91107b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORES (not the best ones) epoch 4 Total loss 0.6710 \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 4 Prec [0.93415638 0.45512506] \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 4 Recall [0.62043047 0.87878788] \n",
      "\n",
      "TEST SCORES (not the best ones) epoch 4 F1 [0.74563745 0.5996769 ] \n",
      "\n",
      "\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7295ea049de6441e9aee2972639b5483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e8850beaab4546bc6f74116ae22c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe90a6f58314fd394eed5414b639359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68612100748d4c978fb6f324f80e07e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 5 Total loss 0.1901 \n",
      "\n",
      "TRAIN SCORES epoch 5 Prec [0.95703793 0.93348602] \n",
      "\n",
      "TRAIN SCORES epoch 5 Recall [0.93172691 0.95817416] \n",
      "\n",
      "TRAIN SCORES epoch 5 F1 [0.94421283 0.94566899] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac81c7a2ba3d4f60bb7fd7ed907e8de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 5 Total loss 0.6008 \n",
      "\n",
      "VAL SCORES epoch 5 Prec [0.82093023 0.60519126] \n",
      "\n",
      "VAL SCORES epoch 5 Recall [0.78560831 0.65727003] \n",
      "\n",
      "VAL SCORES epoch 5 F1 [0.80288097 0.63015647] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 3 out of 7 \u001b[0m\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28c8012018b4454bb8ae961291f5d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb679fd0125b4fbe8d04e9a89ed34ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1252d1aa44f844e48ba3e3ed2ce168e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ddb5e147cd4fa6ba006bb12d51d3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 6 Total loss 0.1375 \n",
      "\n",
      "TRAIN SCORES epoch 6 Prec [0.96811997 0.95545463] \n",
      "\n",
      "TRAIN SCORES epoch 6 Recall [0.95484377 0.96855716] \n",
      "\n",
      "TRAIN SCORES epoch 6 F1 [0.96143604 0.96196128] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5fe04346d84bfab281860b5f7ee7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 6 Total loss 0.6554 \n",
      "\n",
      "VAL SCORES epoch 6 Prec [0.81893939 0.61965812] \n",
      "\n",
      "VAL SCORES epoch 6 Recall [0.80192878 0.64540059] \n",
      "\n",
      "VAL SCORES epoch 6 F1 [0.81034483 0.63226744] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 4 out of 7 \u001b[0m\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49eab5fd75e64c7cbc9e00a28a25c01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79b096a24d548459ae55aca65c5b610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b633595588542eb83bc78d1cadd76ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6894551549940a3a50677df422801ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 7 Total loss 0.1258 \n",
      "\n",
      "TRAIN SCORES epoch 7 Prec [0.97499754 0.97036748] \n",
      "\n",
      "TRAIN SCORES epoch 7 Recall [0.97022235 0.97511999] \n",
      "\n",
      "TRAIN SCORES epoch 7 F1 [0.97260408 0.97273793] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0f0ef0fdff40818c801e7053e68441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 7 Total loss 0.6439 \n",
      "\n",
      "VAL SCORES epoch 7 Prec [0.80931264 0.62182362] \n",
      "\n",
      "VAL SCORES epoch 7 Recall [0.81231454 0.61721068] \n",
      "\n",
      "VAL SCORES epoch 7 F1 [0.81081081 0.61950856] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 5 out of 7 \u001b[0m\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51d0fbbabb442c4ac88721b4b2a2dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef4dc42651e4792b1d215c4895796cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c07d71c2974c61a48e69f1b7117349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cb5a13e90948e0b55e03d81a3a2c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 8 Total loss 0.1246 \n",
      "\n",
      "TRAIN SCORES epoch 8 Prec [0.98854271 0.9643676 ] \n",
      "\n",
      "TRAIN SCORES epoch 8 Recall [0.96346361 0.98883338] \n",
      "\n",
      "TRAIN SCORES epoch 8 F1 [0.97584206 0.97644726] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4afaede839548d8b97445f5625a9a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 8 Total loss 0.6695 \n",
      "\n",
      "VAL SCORES epoch 8 Prec [0.81868132 0.59224599] \n",
      "\n",
      "VAL SCORES epoch 8 Recall [0.77373887 0.65727003] \n",
      "\n",
      "VAL SCORES epoch 8 F1 [0.7955759 0.6230661] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 6 out of 7 \u001b[0m\n",
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af2cdb5a35a47ae94142b1b07d41e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "delta training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT!!! Shared variable is shared by encoder_input_embeddings and decoder_input_embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb16b977fb44f2a839d4fffb23af76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68a8dd015f947b7b494e8ab2ea716a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gamma training:   0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faea28007c384ffdab92bc2c057d360c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1021 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORES epoch 9 Total loss 0.0950 \n",
      "\n",
      "TRAIN SCORES epoch 9 Prec [0.98850575 0.9774356 ] \n",
      "\n",
      "TRAIN SCORES epoch 9 Recall [0.977177   0.98863748] \n",
      "\n",
      "TRAIN SCORES epoch 9 F1 [0.98280873 0.98300463] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1368b016d990499e86f7670ac9455136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL SCORES epoch 9 Total loss 0.7262 \n",
      "\n",
      "VAL SCORES epoch 9 Prec [0.81188119 0.6022567 ] \n",
      "\n",
      "VAL SCORES epoch 9 Recall [0.79080119 0.63353116] \n",
      "\n",
      "VAL SCORES epoch 9 F1 [0.80120256 0.61749819] \n",
      "\n",
      "\n",
      "\u001b[93m EarlyStopping counter: 7 out of 7 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "negative protobart\n",
    "\"\"\"\n",
    "from transformers.optimization import AdamW\n",
    "optim=AdamW(model.parameters(),lr=3e-5,weight_decay=0.01,eps=1e-8)\n",
    "f=open(logs_path,\"w\")\n",
    "f.writelines([\"\"])\n",
    "f.close()\n",
    "val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(val_dl,model)\n",
    "epoch=-1\n",
    "print_logs(logs_path,\"VAL SCORES\",epoch,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "es=EarlyStopping(-np.inf,patience=7,path=save_path,save_epochwise=False)\n",
    "n_iters=1000\n",
    "gamma=2\n",
    "delta=1\n",
    "kappa=1\n",
    "p1_lamb=0.9\n",
    "p2_lamb=0.9\n",
    "p3_lamb=0.9\n",
    "for iter_ in range(n_iters):\n",
    "    total_loss = 0\n",
    "    \"\"\"\n",
    "    During Delta, We want decoder to become better at decoding the trained encoder\n",
    "    and Prototypes to become closer to some encoded representation. And that's why it makes \n",
    "    sense to use l_p1 loss and not l_p2 loss.\n",
    "    losses- rc_loss, l_p1 loss\n",
    "    trainable- decoder and prototypes\n",
    "    details- makes pos_prototypes closer to pos_egs and neg_protos closer to neg_egs \n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.set_encoder_status(status=False)\n",
    "    model.set_decoder_status(status=False)\n",
    "    model.set_protos_status(status=True)\n",
    "    model.set_classfn_status(status=False)\n",
    "    model.set_shared_status(status=True)\n",
    "\n",
    "    for epoch in range(delta):\n",
    "        train_loader = tqdm(train_dl, total=len(train_dl), unit=\"batches\", desc=\"delta training\")\n",
    "        for batch in train_loader:\n",
    "            input_ids, attn_mask, y = batch\n",
    "            classfn_out, loss = model(input_ids, attn_mask, y, use_decoder=0, use_classfn=0,\n",
    "                                      use_rc=0, use_p1=1, use_p2=0, use_p3=0,\n",
    "                                      rc_loss_lamb=1.0, p1_lamb=p1_lamb, p2_lamb=p2_lamb,\n",
    "                                      p3_lamb=p3_lamb,distmask_lp1=1,distmask_lp2=1,\n",
    "                                      random_mask_for_distanceMat=None)\n",
    "            optim.zero_grad()\n",
    "            loss[0].backward()\n",
    "            optim.step()\n",
    "    \"\"\"\n",
    "    During gamma, we only want to improve the classification performance. Therefore we will\n",
    "    improve encoder to become closer to the prototypes, at the same time also improving\n",
    "    the classification accuracy. That's why encoder and classification layer must be trainabl\n",
    "    together without segrregating pos and neg examples.\n",
    "    Only Encoder and Classfn are trainable\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.set_encoder_status(status=True)\n",
    "    model.set_decoder_status(status=False)\n",
    "    model.set_protos_status(status=False)\n",
    "    model.set_classfn_status(status=True)\n",
    "    model.set_shared_status(status=True)\n",
    "\n",
    "    for epoch in range(gamma):\n",
    "        train_loader = tqdm(train_dl, total=len(train_dl), unit=\"batches\", desc=\"gamma training\")\n",
    "        for batch in train_loader:\n",
    "            input_ids, attn_mask, y = batch\n",
    "            classfn_out, loss = model(input_ids, attn_mask, y, use_decoder=0, use_classfn=1,\n",
    "                                      use_rc=0, use_p1=0, use_p2=1,\n",
    "                                      rc_loss_lamb=1., p1_lamb=p1_lamb,p2_lamb=p2_lamb,\n",
    "                                      distmask_lp1 = 1, distmask_lp2 = 1)\n",
    "            optim.zero_grad()\n",
    "            loss[0].backward()\n",
    "            optim.step()\n",
    "\n",
    "    val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(train_dl,model)\n",
    "    print_logs(logs_path,\"TRAIN SCORES\",iter_,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "    es.activate(mac_val_f1[0],mac_val_f1[1])\n",
    "\n",
    "    val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(val_dl,model)\n",
    "    print_logs(logs_path,\"VAL SCORES\",iter_,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)        \n",
    "    es(0.5*(mac_val_f1[1]+mac_val_f1[0]),epoch,model)\n",
    "    if es.early_stop:\n",
    "        break\n",
    "    if es.improved:\n",
    "        \"\"\"\n",
    "        Below using \"val_\" prefix but the dl is that of test.\n",
    "        \"\"\"\n",
    "        val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(test_dl,model)\n",
    "        print_logs(logs_path,\"TEST SCORES\",iter_,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)\n",
    "    elif (iter_+1)%5==0:\n",
    "        \"\"\"\n",
    "        Below using \"val_\" prefix but the dl is that of test.\n",
    "        \"\"\"\n",
    "        val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1=evaluate(test_dl,model)\n",
    "        print_logs(logs_path,\"TEST SCORES (not the best ones)\",iter_,val_loss,mac_val_prec,mac_val_rec,mac_val_f1,mic_val_prec,mic_val_rec,mic_val_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototex",
   "language": "python",
   "name": "prototex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
